Metadata-Version: 2.4
Name: ai-critic
Version: 0.2.2
Summary: Fast AI evaluator for scikit-learn models
Author-email: Luiz Seabra <filipedemarco@yahoo.com>
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: scikit-learn

# ai-critic: Automated Risk Auditor for Machine Learning Models

[![PyPI version](https://img.shields.io/pypi/v/ai-critic.svg)](https://pypi.org/project/ai-critic/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Versions](https://img.shields.io/pypi/pyversions/ai-critic.svg)](https://pypi.org/project/ai-critic/)

O **ai-critic** √© um auditor de risco automatizado baseado em heur√≠sticas para modelos de Machine Learning. Ele avalia modelos treinados antes da implanta√ß√£o e traduz riscos t√©cnicos complexos em decis√µes claras e centradas no ser humano.

Diferente das ferramentas tradicionais que focam apenas em m√©tricas de desempenho, o **ai-critic** adota uma postura c√©tica por design, respondendo √† pergunta fundamental: **‚ÄúEste modelo pode ser implantado com seguran√ßa?‚Äù**

---

## üöÄ O que √© o ai-critic?

O `ai-critic` avalia modelos treinados antes da implanta√ß√£o, analisando quatro √°reas principais de risco:

*   **Integridade dos Dados:** (*data leakage*, desequil√≠brio, NaNs).
*   **Estrutura do Modelo:** (risco de *overfitting*, complexidade, configura√ß√µes suspeitas).
*   **Comportamento de Valida√ß√£o:** (pontua√ß√µes suspeitamente perfeitas de cross-validation).
*   **Robustez:** (sensibilidade a ru√≠do e estabilidade do modelo).

Os resultados s√£o organizados em tr√™s camadas sem√¢nticas para diferentes *stakeholders*:
*   **Executiva:** Decis√µes para stakeholders e gerentes.
*   **T√©cnica:** Diagn√≥sticos para engenheiros de ML.
*   **Detalhada:** Sa√≠da completa de m√©tricas e an√°lises t√©cnicas, incluindo gr√°ficos opcionais.

---

## üéØ Por que o ai-critic Existe: Filosofia Central

A maioria das ferramentas de ML tradicionais assume que m√©tricas s√£o a verdade absoluta, confia cegamente na valida√ß√£o cruzada e entrega n√∫meros brutos sem interpreta√ß√£o.

O **ai-critic** √© c√©tico por design. Ele trata:
*   **Pontua√ß√µes perfeitas** como sinais de alerta, n√£o necessariamente sucesso.
*   **M√©tricas de robustez** como dependentes do contexto.
*   **Implanta√ß√£o** como uma decis√£o de gest√£o de risco, n√£o apenas uma meta t√©cnica.

A filosofia central √©: **M√©tricas n√£o falham modelos ‚Äî o contexto falha.** O `ai-critic` aplica heur√≠sticas de racioc√≠nio humano:
*   ‚ÄúIsso √© bom demais para ser verdade?‚Äù
*   ‚ÄúIsso pode estar vazando o alvo (*target*)?‚Äù
*   ‚ÄúA robustez importa se a linha de base estiver errada?‚Äù

---

## üõ†Ô∏è Instala√ß√£o

Instale o `ai-critic` via pip:

```bash
pip install ai-critic
```

**Requisitos:**
*   Python ‚â• 3.8
*   `scikit-learn`
*   `matplotlib`, `seaborn`, `numpy`, `pandas` (para visualiza√ß√µes opcionais)

---

## üí° In√≠cio R√°pido

Audite seu modelo treinado em apenas algumas linhas:

```python
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from ai_critic import AICritic

# 1. Carregar dados e treinar um modelo (exemplo)
X, y = load_breast_cancer(return_X_y=True)
model = RandomForestClassifier(max_depth=20, random_state=42)
model.fit(X, y)

# 2. Inicializar e avaliar com ai-critic
critic = AICritic(model, X, y)

# Realiza√ß√£o de avalia√ß√£o completa (padr√£o view="all")
report = critic.evaluate(plot=True)
print(report)
```

---

## üß© Sa√≠da Multi-Camadas

O `ai-critic` estrutura os resultados em camadas de decis√£o claras atrav√©s do par√¢metro `view`.

### üîπ Visualiza√ß√£o Executiva (`view="executive"`)
Projetado para stakeholders e gestores. Sem jarg√£o t√©cnico.

```python
critic.evaluate(view="executive")
```

**Exemplo de Sa√≠da:**
```json
{
  "verdict": "‚ùå N√£o Confi√°vel",
  "risk_level": "high",
  "deploy_recommended": false,
  "main_reason": "Forte evid√™ncia de vazamento de dados inflando o desempenho do modelo."
}
```

### üîπ Visualiza√ß√£o T√©cnica (`view="technical"`)
Projetado para engenheiros de ML. Focado em diagn√≥sticos e a√ß√µes corretivas.

```python
critic.evaluate(view="technical")
```

**Exemplo de Sa√≠da:**
```json
{
  "key_risks": [
    "Vazamento de dados suspeito devido √† correla√ß√£o quase perfeita entre recurso e alvo.",
    "Pontua√ß√£o de valida√ß√£o cruzada perfeita detectada (estatisticamente improv√°vel).",
    "A profundidade da √°rvore pode ser muito alta para o tamanho do conjunto de dados."
  ],
  "model_health": {
    "data_leakage": true,
    "suspicious_cv": true,
    "structural_risk": true,
    "robustness_verdict": "misleading"
  },
  "recommendations": [
    "Auditar e remover recursos com vazamento.",
    "Reduzir a complexidade do modelo.",
    "Executar novamente a valida√ß√£o ap√≥s a mitiga√ß√£o do vazamento."
  ]
}
```

### üîπ Visualiza√ß√£o Detalhada (`view="details"`)
Projetado para auditoria, depura√ß√£o e conformidade. Agrega todos os outputs dos m√≥dulos internos.

```python
details = critic.evaluate(view="details")
print(details["data"]["class_balance"])
print(details["robustness"]["performance_drop"])
```

### üîπ Visualiza√ß√£o Combinada (`view="all"`)
Retorna todas as tr√™s camadas em um √∫nico dicion√°rio, facilitando a integra√ß√£o com pipelines de CI/CD.

---

## üìä Visualiza√ß√µes e Gr√°ficos

Ao definir `plot=True` no m√©todo `evaluate()`, o `ai-critic` gera automaticamente:
*   **Heatmap de Correla√ß√£o:** Identifica√ß√£o visual de vazamento de dados.
*   **Learning Curve:** Diagn√≥stico de overfitting e necessidade de mais dados.
*   **Gr√°fico de Robustez:** Visualiza√ß√£o da queda de performance sob ru√≠do.

---

## ‚öôÔ∏è API Principal e Modulariza√ß√£o

### `AICritic(model, X, y)`
*   `model`: Modelo `scikit-learn` treinado.
*   `X`: Matriz de recursos.
*   `y`: Vetor alvo.

### `evaluate(view="all", plot=False)`
*   `view`: Camada de sa√≠da (`"executive"`, `"technical"`, `"details"`, `"all"` ou lista customizada).
*   `plot`: `True` para gerar gr√°ficos autom√°ticos.

### Uso Modular (Avan√ßado)
Cada m√≥dulo retorna um dicion√°rio padronizado consistente:
```python
from ai_critic.evaluators import data, config, performance, robustness

data_report = data.evaluate(X, y, plot=True)
config_report = config.evaluate(model, n_samples=data_report["n_samples"], n_features=data_report["n_features"])
```

---

## üß† O que o ai-critic Detecta

| Categoria | Riscos Detectados |
| :--- | :--- |
| **üîç Dados** | Vazamento de alvo via correla√ß√£o, NaNs, desequil√≠brio de classes. |
| **üß± Estrutura** | √Årvores excessivamente complexas, altas taxas de recurso/amostra, configura√ß√µes suspeitas. |
| **üìà Valida√ß√£o** | Pontua√ß√µes de CV suspeitosamente perfeitas, vari√¢ncia irreal. |
| **üß™ Robustez** | Sensibilidade a ru√≠do, robustez enganosa (stable, fragile, misleading). |

---

## üõ°Ô∏è Melhores Pr√°ticas

*   **CI/CD:** Use a Visualiza√ß√£o Executiva como um port√£o de qualidade automatizado.
*   **Debugging:** Use a Visualiza√ß√£o T√©cnica durante a itera√ß√£o do modelo.
*   **Compliance:** Utilize a Visualiza√ß√£o Detalhada para rastreabilidade e auditoria.
*   **Ceticismo:** Nunca confie cegamente em pontua√ß√µes de CV perfeitas.

---

## üß≠ Casos de Uso T√≠picos
*   Auditorias de modelo pr√©-implanta√ß√£o.
*   Governan√ßa e conformidade de ML.
*   Port√µes de modelo em pipelines CI/CD.
*   Explica√ß√£o de riscos para stakeholders n√£o t√©cnicos.

---

## üìÑ Licen√ßa

Distribu√≠do sob a **MIT License**.

---

## üß† Nota Final

O **ai-critic** n√£o √© uma ferramenta de benchmarking. √â uma **ferramenta de decis√£o**. Se um modelo falhar aqui, n√£o significa que seja ruim ‚Äî significa que **n√£o deve ser confi√°vel ainda**.
